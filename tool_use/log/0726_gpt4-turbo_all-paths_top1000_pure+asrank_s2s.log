nohup: ignoring input
  0%|          | 0/5000 [00:00<?, ?it/s]  0%|          | 21/5000 [00:51<3:21:37,  2.43s/it]  0%|          | 22/5000 [01:36<7:08:47,  5.17s/it]  0%|          | 23/5000 [02:13<10:48:12,  7.81s/it]  0%|          | 24/5000 [02:46<14:31:03, 10.50s/it]  0%|          | 25/5000 [08:49<78:51:53, 57.07s/it]  1%|          | 26/5000 [09:28<74:46:35, 54.12s/it]  1%|          | 27/5000 [10:13<72:36:50, 52.57s/it]  1%|          | 28/5000 [11:10<73:51:16, 53.47s/it]  1%|          | 29/5000 [11:45<67:58:24, 49.23s/it]  1%|          | 30/5000 [12:33<67:23:03, 48.81s/it]  1%|          | 31/5000 [13:18<66:03:09, 47.85s/it]  1%|          | 32/5000 [14:04<65:27:58, 47.44s/it]  1%|          | 33/5000 [15:04<70:09:10, 50.85s/it]  1%|          | 34/5000 [15:52<68:52:52, 49.93s/it]  1%|          | 35/5000 [16:42<69:14:04, 50.20s/it]  1%|          | 36/5000 [17:27<67:08:59, 48.70s/it]  1%|          | 37/5000 [18:24<70:19:34, 51.01s/it]  1%|          | 38/5000 [19:13<69:39:14, 50.53s/it]  1%|          | 39/5000 [20:01<68:24:58, 49.65s/it]  1%|          | 40/5000 [20:51<68:25:31, 49.66s/it]  1%|          | 41/5000 [21:30<64:21:38, 46.72s/it]  1%|          | 42/5000 [22:06<59:38:25, 43.30s/it]  1%|          | 43/5000 [23:08<67:14:14, 48.83s/it]  1%|          | 44/5000 [24:17<75:45:24, 55.03s/it]  1%|          | 45/5000 [25:03<71:52:27, 52.22s/it]  1%|          | 46/5000 [25:36<64:03:17, 46.55s/it]  1%|          | 47/5000 [26:17<61:37:03, 44.79s/it]  1%|          | 48/5000 [26:57<59:56:11, 43.57s/it]  1%|          | 49/5000 [27:33<56:43:39, 41.25s/it]  1%|          | 50/5000 [28:25<61:00:04, 44.36s/it]  1%|          | 51/5000 [29:27<68:19:25, 49.70s/it]  1%|          | 52/5000 [30:07<64:28:13, 46.91s/it]  1%|          | 53/5000 [31:01<67:23:02, 49.04s/it]  1%|          | 54/5000 [31:53<68:12:36, 49.65s/it]  1%|          | 55/5000 [32:31<63:47:29, 46.44s/it]  1%|          | 56/5000 [33:11<60:48:42, 44.28s/it]  1%|          | 57/5000 [34:02<63:36:06, 46.32s/it]  1%|          | 58/5000 [34:45<62:27:43, 45.50s/it]  1%|          | 59/5000 [35:20<57:52:12, 42.16s/it]  1%|          | 60/5000 [35:57<55:38:41, 40.55s/it]  1%|          | 61/5000 [41:50<184:19:04, 134.35s/it]  1%|          | 62/5000 [42:30<145:23:33, 106.00s/it]  1%|▏         | 63/5000 [43:06<116:40:40, 85.08s/it]   1%|▏         | 64/5000 [43:48<98:58:14, 72.18s/it]   1%|▏         | 65/5000 [44:21<83:01:26, 60.56s/it]  1%|▏         | 66/5000 [45:00<74:02:04, 54.02s/it]  1%|▏         | 67/5000 [45:59<75:51:38, 55.36s/it]  1%|▏         | 68/5000 [46:50<74:23:20, 54.30s/it]  1%|▏         | 69/5000 [47:30<68:07:00, 49.73s/it]  1%|▏         | 70/5000 [48:15<66:24:54, 48.50s/it]  1%|▏         | 71/5000 [49:24<74:53:01, 54.69s/it]  1%|▏         | 72/5000 [50:07<69:56:52, 51.10s/it]  1%|▏         | 73/5000 [50:44<64:01:24, 46.78s/it]  1%|▏         | 74/5000 [51:21<59:58:29, 43.83s/it]  2%|▏         | 75/5000 [52:19<65:47:38, 48.09s/it]  2%|▏         | 76/5000 [53:18<70:24:55, 51.48s/it]  2%|▏         | 77/5000 [54:02<67:17:36, 49.21s/it]  2%|▏         | 78/5000 [54:37<61:27:40, 44.95s/it]  2%|▏         | 79/5000 [55:13<57:54:57, 42.37s/it]  2%|▏         | 80/5000 [56:09<63:29:55, 46.46s/it]  2%|▏         | 81/5000 [56:59<64:48:39, 47.43s/it]  2%|▏         | 82/5000 [57:50<66:01:27, 48.33s/it]  2%|▏         | 83/5000 [58:44<68:37:30, 50.24s/it]  2%|▏         | 84/5000 [59:28<66:08:10, 48.43s/it]  2%|▏         | 85/5000 [1:00:16<65:37:34, 48.07s/it]  2%|▏         | 86/5000 [1:01:03<65:12:38, 47.77s/it]  2%|▏         | 87/5000 [1:01:58<68:19:33, 50.07s/it]  2%|▏         | 88/5000 [1:02:43<65:59:15, 48.36s/it]  2%|▏         | 89/5000 [1:03:30<65:37:35, 48.11s/it]  2%|▏         | 89/5000 [1:03:42<58:35:20, 42.95s/it]
Retrying in 1 seconds due to connection error: Connection error.
Traceback (most recent call last):
  File "/home/yyc/BGP-Woodpecker/BGPAgent/tool_use/as_relationship_inference.py", line 404, in <module>
    model_series = "llama3.1"
    ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yyc/BGP-Woodpecker/BGPAgent/tool_use/as_relationship_inference.py", line 344, in main
    # 从多个as_path获取到各个as的信息，as_paths是一个列表，每个列表的单个元素是一个字符串，
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yyc/BGP-Woodpecker/BGPAgent/tool_use/as_relationship_inference.py", line 165, in get_llm_user_content
    # gemma_7b_value = get_client_chat_completion_value(
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/yyc/BGP-Woodpecker/BGPAgent/tool_use/as_relationship_inference.py", line 30, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/yyc/BGP-Woodpecker/BGPAgent/tool_use/as_relationship_inference.py", line 72, in get_client_chat_completion_value
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/miniconda3/lib/python3.11/site-packages/openai/_utils/_utils.py", line 277, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/miniconda3/lib/python3.11/site-packages/openai/resources/chat/completions.py", line 643, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/miniconda3/lib/python3.11/site-packages/openai/_base_client.py", line 1261, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/miniconda3/lib/python3.11/site-packages/openai/_base_client.py", line 942, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/home/miniconda3/lib/python3.11/site-packages/openai/_base_client.py", line 997, in _request
    return self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/miniconda3/lib/python3.11/site-packages/openai/_base_client.py", line 1074, in _retry_request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/home/miniconda3/lib/python3.11/site-packages/openai/_base_client.py", line 1026, in _request
    return self._retry_request(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/miniconda3/lib/python3.11/site-packages/openai/_base_client.py", line 1074, in _retry_request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/home/miniconda3/lib/python3.11/site-packages/openai/_base_client.py", line 1041, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.InternalServerError: Error code: 503 - {'error': {'message': '当前分组 default 下对于模型 gpt-4-turbo 无可用渠道 (request id: 202407261417206559318765097329)', 'type': 'Aihubmix_api_error'}}
